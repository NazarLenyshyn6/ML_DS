{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a945f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f2b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff:  {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53eca76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor([6.0275], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(111111)\n",
    "X = torch.randn((10, 10), generator=g, requires_grad=True)\n",
    "y = torch.randn((10, 1), generator=g, requires_grad=True)\n",
    "W = torch.randn((10, 1), generator=g, requires_grad=True)\n",
    "b = torch.randn(1, generator=g, requires_grad=True)\n",
    "\n",
    "# Math Expression\n",
    "matmul = X @ W\n",
    "pred = matmul + b\n",
    "diff = y - pred\n",
    "diff2 = diff ** 2 \n",
    "loss = diff2.mean(0)\n",
    "\n",
    "for t in [matmul, pred, diff, diff2, loss]:\n",
    "    t.retain_grad()\n",
    "\n",
    "print(f'Loss:', loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bc5121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1]), torch.Size([10, 10]), torch.Size([10, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = m * n, W = n * 1,  matmul = m  * 1\n",
    "# matmul = X @ W\n",
    "# dmatmul / dX = W * dmatmul = (10, 10) = (10, 1) @ (1, 10) = (10, 10)\n",
    "# dmatmul / dW = X * dmatmul = (n * 1) = (n * m) @ (m * 1) = (n, 1)\n",
    " \n",
    "matmul.shape, X.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba0accb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff2           | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "ddiff           | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "dy              | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "dpred           | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "dmatmul         | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "db              | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "dX              | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "dW              | exact: True  | approximate: True  | maxdiff:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Exersice: Let's backpropagate through that entire math expression and \n",
    "# compare calculated gradiens with Pytorch\n",
    "# calculates ones assuming that they are correct\n",
    "\n",
    "ddiff2 = torch.ones_like(diff) * (1.0 / diff.shape[0]) * 1.0\n",
    "ddiff = 2 * diff * ddiff2\n",
    "dy = torch.ones_like(y) * ddiff\n",
    "dpred = -torch.ones_like(pred) * ddiff\n",
    "dmatmul = torch.ones_like(matmul) * dpred\n",
    "db = (torch.ones_like(b) * dpred).sum(0)\n",
    "dX = dmatmul @ W.T\n",
    "dW = X.T @ dmatmul\n",
    "\n",
    "cmp('diff2', ddiff2, diff2)\n",
    "cmp('ddiff', ddiff, diff)\n",
    "cmp('dy', dy, y)\n",
    "cmp('dpred', dpred, pred)\n",
    "cmp('dmatmul', dmatmul, matmul)\n",
    "cmp('db', db, b)\n",
    "cmp('dX', dX, X)\n",
    "cmp('dW', dW, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217d1c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor([1.1765], grad_fn=<MeanBackward1>)\n",
      "Torch Loss: tensor(1.1765, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(111111)\n",
    "X = torch.randn((10, 10), generator=g, requires_grad=True)\n",
    "y = torch.randint(0, 2, (10,1), dtype=torch.float32, generator=g, requires_grad=True)\n",
    "W = torch.randn((10, 1), generator=g, requires_grad=True)\n",
    "b = torch.randn(1, generator=g, requires_grad=True)\n",
    "\n",
    "logits = X @ W + b\n",
    "neg_logits = -logits\n",
    "exp_neg_logits = neg_logits.exp()\n",
    "probs = 1 / (1 + exp_neg_logits)\n",
    "positive_probs = probs * y\n",
    "negative_probs = (1 - probs) * (1 - y)\n",
    "new_probs = positive_probs + negative_probs\n",
    "log_probs = new_probs.log()\n",
    "neg_log_probs = -log_probs\n",
    "loss = neg_log_probs.mean(0)\n",
    "\n",
    "for t in [logits, neg_logits, exp_neg_logits, probs,  positive_probs, negative_probs, new_probs, log_probs, neg_log_probs, loss]:\n",
    "    t.retain_grad()\n",
    "print('Loss:', loss)\n",
    "print(f'Torch Loss:', F.binary_cross_entropy_with_logits(logits, y))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b2fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_log_probs   | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "log_probs       | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "new_probs       | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "positive_probs  | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "negative_probs  | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "probs           | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "y               | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "exp_neg_logits  | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "neg_logits      | exact: False | approximate: True  | maxdiff:  7.450580596923828e-09\n",
      "logits          | exact: False | approximate: True  | maxdiff:  7.450580596923828e-09\n",
      "X               | exact: False | approximate: True  | maxdiff:  1.4901161193847656e-08\n",
      "W               | exact: False | approximate: True  | maxdiff:  5.960464477539063e-08\n",
      "b               | exact: True  | approximate: True  | maxdiff:  0.0\n"
     ]
    }
   ],
   "source": [
    "dneg_log_probs = torch.ones_like(neg_log_probs) * (1.0 / neg_log_probs.shape[0])\n",
    "dlog_probs = -torch.ones_like(log_probs) * dneg_log_probs\n",
    "dnew_probs =  (1.0 / new_probs) * dlog_probs\n",
    "dpositive_probs = torch.ones_like(positive_probs) * dnew_probs\n",
    "dnegative_probs = torch.ones_like(negative_probs) * dnew_probs\n",
    "dprobs = -(1 - y) * torch.ones_like(probs) * dnegative_probs\n",
    "dy = -(1 - probs) * torch.ones_like(y) * dnegative_probs\n",
    "dprobs += y * dpositive_probs\n",
    "dy += probs * dpositive_probs\n",
    "dexp_neg_logits = -(1 / (1 + exp_neg_logits)**2) * dprobs\n",
    "dneg_logits = exp_neg_logits * dexp_neg_logits\n",
    "dlogits = -torch.ones_like(logits) * dneg_logits\n",
    "dX = dlogits @ W.T\n",
    "dW = X.T @ dlogits\n",
    "db = dlogits.sum(0, keepdim=True)\n",
    "\n",
    "cmp('neg_log_probs', dneg_log_probs, neg_log_probs)\n",
    "cmp('log_probs', dlog_probs, log_probs)\n",
    "cmp('new_probs', dnew_probs, new_probs)\n",
    "cmp('positive_probs', dpositive_probs, positive_probs)\n",
    "cmp('negative_probs', dnegative_probs, negative_probs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('y', dy, y)\n",
    "cmp('exp_neg_logits', dexp_neg_logits, exp_neg_logits)\n",
    "cmp('neg_logits', dneg_logits, neg_logits)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('X', dX, X)\n",
    "cmp('W', dW, W)\n",
    "cmp('b', db, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb88cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((5,5), generator=g, requires_grad=True)\n",
    "w = torch.randn((5,1), generator=g, requires_grad=True)\n",
    "\n",
    "pre = x @ w \n",
    "res = torch.relu(pre)\n",
    "loss = res.mean(0)\n",
    "\n",
    "for t in [x, w, pre, res, loss]:\n",
    "    t.retain_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0716b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res             | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "pre             | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "x               | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "w               | exact: True  | approximate: True  | maxdiff:  0.0\n"
     ]
    }
   ],
   "source": [
    "dres = torch.ones_like(res) / res.shape[0]\n",
    "dpre = (pre > 0).int() * dres\n",
    "dx = dpre @ w.T\n",
    "dw = x.T @ dpre\n",
    "\n",
    "cmp('res', dres, res)\n",
    "cmp('pre', dpre, pre)\n",
    "cmp('x', dx, x)\n",
    "cmp('w', dw, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c175c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1231394037604332\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(111111)\n",
    "X = torch.randn((100, 10), generator=g, requires_grad=True)\n",
    "W1= torch.randn((10, 200), generator=g, requires_grad=True)\n",
    "b1 = torch.randn(200, generator=g, requires_grad=True)\n",
    "W2 = torch.randn((200, 300),  generator=g, requires_grad=True)\n",
    "b2 = torch.randn(300, generator=g, requires_grad=True)\n",
    "W3 = torch.randn((300, 100), generator=g, requires_grad=True)\n",
    "b3 = torch.randn(100, generator=g, requires_grad=True)\n",
    "\n",
    "\n",
    "# Linear layer 1\n",
    "h1_preact = X @ W1 + b1 # +\n",
    "# Activation 1\n",
    "h1 = torch.relu(h1_preact) # +\n",
    "# Linear layer 2\n",
    "h2_preact = h1 @ W2  + b2 # +\n",
    "# Activation 2\n",
    "h2 = torch.sigmoid(h2_preact) # +\n",
    "# Linear layer 3\n",
    "h3_preact = h2 @ W3 + b3 # \n",
    "# Activation 3\n",
    "h3 = h3_preact.exp() # +\n",
    "h3_sum = h3.sum(1, keepdim=True) # +\n",
    "h3_sum_inv = h3_sum**-1 # +\n",
    "probs = h3 * h3_sum_inv # +\n",
    "# Outputs\n",
    "outputs = probs.max(1, keepdim=True).values # +\n",
    "# Cross Entropy Loss\n",
    "logits = outputs.log() # +\n",
    "loss = -logits.mean()  # +\n",
    "\n",
    "for t in [h1_preact, h1, h2_preact, h2, h3_preact,  h3, h3_sum, h3_sum_inv, probs, outputs, logits, loss]:\n",
    "    t.retain_grad()\n",
    "    \n",
    "print(f'Loss:',  loss.item())\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d27740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "outputs         | exact: False | approximate: True  | maxdiff:  1.862645149230957e-09\n",
      "probs           | exact: False | approximate: True  | maxdiff:  1.862645149230957e-09\n",
      "h3_sum_inv      | exact: False | approximate: True  | maxdiff:  274877906944.0\n",
      "h3_sum          | exact: False | approximate: True  | maxdiff:  4.235164736271502e-22\n",
      "h3              | exact: False | approximate: True  | maxdiff:  4.235164736271502e-22\n",
      "h3_preact       | exact: False | approximate: True  | maxdiff:  1.1827978596556932e-09\n",
      "dh2             | exact: False | approximate: True  | maxdiff:  3.725290298461914e-09\n",
      "dw3             | exact: False | approximate: True  | maxdiff:  1.4901161193847656e-08\n",
      "db3             | exact: False | approximate: True  | maxdiff:  7.450580596923828e-09\n",
      "dh2_preact      | exact: False | approximate: True  | maxdiff:  9.313225746154785e-10\n",
      "dh1             | exact: False | approximate: True  | maxdiff:  5.587935447692871e-09\n",
      "dw2             | exact: False | approximate: True  | maxdiff:  7.450580596923828e-09\n",
      "db2             | exact: False | approximate: True  | maxdiff:  9.313225746154785e-10\n",
      "dh1_preact      | exact: False | approximate: True  | maxdiff:  5.587935447692871e-09\n",
      "dx              | exact: False | approximate: False | maxdiff:  5.960464477539063e-08\n",
      "dw1             | exact: False | approximate: True  | maxdiff:  1.4901161193847656e-08\n",
      "db1             | exact: False | approximate: True  | maxdiff:  1.4901161193847656e-08\n"
     ]
    }
   ],
   "source": [
    "dlogits = -torch.ones_like(logits) / logits.shape[0]\n",
    "doutputs = (1.0 / outputs) * dlogits\n",
    "dprobs = F.one_hot(probs.max(1).indices, num_classes=probs.shape[1]) * doutputs\n",
    "dh3 = dprobs * h3_sum_inv \n",
    "dh3_sum_inv = (dprobs * h3).sum(1, keepdim=True)\n",
    "dh3_sum = (-1.0 *  h3_sum**-2) * dh3_sum_inv\n",
    "dh3 += torch.ones_like(h3) * dh3_sum \n",
    "dh3_preact = h3  * dh3\n",
    "dh2 = dh3_preact @ W3.T\n",
    "dw3 = h2.T @  dh3_preact\n",
    "db3 = dh3_preact.sum(0)\n",
    "dh2_preact  = h2 * (1 - h2) * dh2\n",
    "dh1 = dh2_preact @ W2.T\n",
    "dw2 = h1.T @  dh2_preact\n",
    "db2 = dh2_preact.sum(0)\n",
    "dh1_preact = (h1_preact > 0).int() * dh1\n",
    "dx = dh1_preact  @  W1.T \n",
    "dw1 = X.T  @ dh1_preact  \n",
    "db1 = dh1_preact.sum(0)\n",
    "\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('outputs', doutputs, outputs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('h3_sum_inv', dh3_sum_inv, h3_sum_inv)\n",
    "cmp('h3_sum', dh3_sum, h3_sum)\n",
    "cmp('h3', dh3, h3)\n",
    "cmp('h3_preact', dh3_preact, h3_preact)\n",
    "\n",
    "\n",
    "cmp('dh2', dh2, h2)\n",
    "cmp('dw3', dw3, W3)\n",
    "cmp('db3', db3,  b3)\n",
    "cmp('dh2_preact', dh2_preact, h2_preact)\n",
    "cmp('dh1', dh1, h1)\n",
    "cmp('dw2', dw2, W2)\n",
    "cmp('db2', db2,  b2)\n",
    "cmp('dh1_preact', dh1_preact, h1_preact)\n",
    "cmp('dx', dx, X)\n",
    "cmp('dw1', dw1, W1)\n",
    "cmp('db1', db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d52fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(X) = X*@W + b + sum(W^2)\n",
    "\n",
    "X = torch.randn((100, 3), generator=g, requires_grad=True)\n",
    "W = torch.randn((3, 1), generator=g, requires_grad=True)\n",
    "b = torch.randn(1, generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438b29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = X @ W + b\n",
    "W_2 = W**2\n",
    "reg = W_2.sum(0)\n",
    "preds = linear + reg\n",
    "pred = preds.mean(0)\n",
    "\n",
    "for t in [linear, W_2, reg, preds, pred]:\n",
    "    t.retain_grad()\n",
    "\n",
    "pred.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dea8fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds           | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "linear          | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "reg             | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "W_2             | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "W               | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "X               | exact: True  | approximate: True  | maxdiff:  0.0\n",
      "b               | exact: True  | approximate: True  | maxdiff:  0.0\n"
     ]
    }
   ],
   "source": [
    "dpreds = torch.ones_like(preds) / preds.shape[0]\n",
    "dlinear = torch.ones_like(linear) * dpreds\n",
    "dreg = (torch.ones_like(linear) * dpreds).sum(0)\n",
    "dW_2 = torch.ones_like(W_2) * dreg\n",
    "dW = 2 * W * dW_2\n",
    "dW += X.T @ dlinear\n",
    "dX = dlinear @ W.T\n",
    "db = dlinear.sum(0)\n",
    "\n",
    "\n",
    "cmp('preds', dpreds,  preds)\n",
    "cmp('linear', dlinear, linear)\n",
    "cmp('reg', dreg, reg)\n",
    "cmp('W_2', dW_2, W_2)\n",
    "cmp('W', dW, W)\n",
    "cmp('X', dX, X)\n",
    "cmp('b',db, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cd6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
